"""
é€šç”¨ Agent æ‰§è¡Œå¾ªç¯
"""

import json
from typing import Any

from nonebot.adapters.onebot.v11 import Bot, MessageEvent

from zhenxun.services.llm import LLMMessage
from zhenxun.services.llm.tools import tool_registry
from zhenxun.services.log import logger

from ..config import base_config
from .session_manager import SessionState, SessionStatus, session_manager


async def _execute_mcp_tool(
    mcp_tool_name: str, sub_tool_name: str, arguments: dict[str, Any]
) -> Any:
    """
    ä¸€ä¸ªç‹¬ç«‹çš„è¾…åŠ©å‡½æ•°ï¼Œç”¨äºä¸´æ—¶è¿æ¥åˆ°MCPæœåŠ¡å™¨å¹¶æ‰§è¡Œå…¶æä¾›çš„å­å·¥å…·ã€‚
    :param mcp_tool_name: çˆ¶MCPå·¥å…·çš„åç§° (å¦‚ 'baidu-map')
    :param sub_tool_name: è¦æ‰§è¡Œçš„å­å·¥å…·çš„åç§° (å¦‚ 'map_geocode')
    :param arguments: å­å·¥å…·çš„å‚æ•°
    """
    logger.info(
        f"âš¡ï¸ æ‰§è¡Œ MCP å·¥å…·: {mcp_tool_name} -> {sub_tool_name}ï¼Œå‚æ•°: {arguments}"
    )
    try:
        from ..tools import MCP_AVAILABLE

        if not MCP_AVAILABLE:
            raise RuntimeError("å°è¯•æ‰§è¡ŒMCPå·¥å…·ï¼Œä½†'mcp'ä¾èµ–æœªå®‰è£…ã€‚")

        import mcp

        llm_tool = tool_registry.get_tool(mcp_tool_name)
        if not llm_tool.mcp_session or not callable(llm_tool.mcp_session):
            raise ValueError(
                f"å·¥å…· '{mcp_tool_name}' ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„ã€å¯è°ƒç”¨çš„MCPå·¥å…·ã€‚"
            )

        session_factory = llm_tool.mcp_session

        async with session_factory() as mcp_session_wrapper:
            if not hasattr(mcp_session_wrapper, "session") or not isinstance(
                mcp_session_wrapper.session, mcp.ClientSession
            ):
                raise TypeError("æ— æ³•ä»åŒ…è£…å™¨ä¸­è·å–åº•å±‚çš„ MCP ClientSessionã€‚")

            client_session: mcp.ClientSession = mcp_session_wrapper.session

            result = await client_session.call_tool(
                name=sub_tool_name, arguments=arguments
            )

            logger.info(f"âœ… å·¥å…· '{sub_tool_name}' æ‰§è¡ŒæˆåŠŸã€‚")
            return result.model_dump()

    except Exception as e:
        logger.error(f"âŒ æ‰§è¡Œ MCP å·¥å…· '{sub_tool_name}' å¤±è´¥: {e}")
        return {"error": f"æ‰§è¡Œå·¥å…·æ—¶å‘ç”Ÿé”™è¯¯: {e!s}"}


async def run_generic_agent_loop(
    session_state: SessionState,
    mcp_tool_name: str,
    system_prompt: str,
    bot: Bot,
    event: MessageEvent,
    model_name: str | None = None,
) -> str:
    """
    æ‰§è¡Œå¯æš‚åœå’Œæ¢å¤çš„é€šç”¨Agentå¾ªç¯ã€‚
    """
    session_state.status = SessionStatus.PROCESSING_AGENT
    ai_instance = session_state.ai_instance
    conversation_history = ai_instance.history

    if not any(msg.role == "system" for msg in conversation_history):
        conversation_history.insert(0, LLMMessage.system(system_prompt))

    mcp_tools = tool_registry.get_tools([mcp_tool_name])

    for i in range(5):
        logger.info(
            f"ğŸ”„ Agent å¾ªç¯ - ç¬¬ {i + 1}/5 è½®ï¼Œä¼šè¯ID: {session_manager._get_session_id(event.get_user_id(), str(getattr(event, 'group_id', None)))}"
        )

        llm_response = await ai_instance.analyze(
            message=None,
            history=conversation_history,
            activated_tools=mcp_tools,
            model=model_name or base_config.get("AGENT_MODEL_NAME"),
        )

        if not llm_response.tool_calls:
            final_response_text = llm_response.text
            conversation_history.append(
                LLMMessage.assistant_text_response(final_response_text)
            )

            if final_response_text and final_response_text.strip().endswith(
                ("?", "ï¼Ÿ")
            ):
                logger.info("âœ… Agent æ­£åœ¨ç­‰å¾…ç”¨æˆ·è¾“å…¥ä»¥ç»§ç»­ã€‚")
                session_state.status = SessionStatus.AWAITING_USER_INPUT
            else:
                logger.info("âœ… Agent å¾ªç¯ç»“æŸï¼Œæ¨¡å‹å·²ç”Ÿæˆæœ€ç»ˆå›å¤ã€‚")
                session_state.status = SessionStatus.IDLE
                session_state.intent = None
            return final_response_text

        conversation_history.append(
            LLMMessage.assistant_tool_calls(llm_response.tool_calls)
        )
        logger.info(f"â›ï¸ Agent å†³å®šè°ƒç”¨ {len(llm_response.tool_calls)} ä¸ªå·¥å…·ã€‚")

        tool_results_messages = []
        for tool_call in llm_response.tool_calls:
            arguments = (
                json.loads(tool_call.function.arguments)
                if isinstance(tool_call.function.arguments, str)
                else tool_call.function.arguments
            )
            tool_result = await _execute_mcp_tool(
                mcp_tool_name=mcp_tool_name,
                sub_tool_name=tool_call.function.name,
                arguments=arguments,
            )
            tool_results_messages.append(
                LLMMessage.tool_response(
                    tool_call_id=tool_call.id,
                    function_name=tool_call.function.name,
                    result=tool_result,
                )
            )

        conversation_history.extend(tool_results_messages)

    logger.warning("Agent å¾ªç¯è¾¾åˆ°æœ€å¤§æ¬¡æ•°ï¼Œæœªèƒ½å¾—å‡ºæœ€ç»ˆç»“è®ºã€‚")
    session_state.status = SessionStatus.IDLE
    session_state.intent = None
    return "æŠ±æ­‰ï¼Œæˆ‘å¤šæ¬¡å°è¯•åä»ç„¶æ— æ³•è§£å†³ä½ çš„é—®é¢˜ã€‚è¯·æ£€æŸ¥æˆ‘çš„å·¥å…·æˆ–ç¨åå†è¯•ã€‚"
