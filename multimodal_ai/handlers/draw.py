import json
from pathlib import Path
import re
import tempfile
import time

import aiofiles
import httpx
from nonebot.adapters.onebot.v11 import (
    Bot,
    GroupMessageEvent,
    MessageEvent,
    MessageSegment,
)
from nonebot.permission import SUPERUSER
from nonebot_plugin_alconna import CommandResult, UniMessage, UniMsg
from nonebot_plugin_alconna.uniseg import Image as UniImage

from zhenxun.services.llm import (
    CommonOverrides,
    LLMMessage,
    generate,
    message_to_unimessage,
    unimsg_to_llm_parts,
)
from zhenxun.services.llm.config import LLMGenerationConfig
from zhenxun.services.llm.types import get_user_friendly_error_message
from zhenxun.services.log import logger

from .. import ai_draw
from ..config import base_config
from ..core.queue_manager import draw_queue_manager


async def send_images_as_forward(
    bot: Bot, event: MessageEvent, images: list, prompt: str
):
    """å‘é€å›¾ç‰‡ä½œä¸ºåˆå¹¶è½¬å‘æ¶ˆæ¯"""
    try:
        forward_messages = []

        forward_messages.append(
            {
                "type": "node",
                "data": {
                    "name": "AIç»˜å›¾åŠ©æ‰‹",
                    "uin": str(bot.self_id),
                    "content": [MessageSegment.text(f"ğŸ“ {prompt}")],
                },
            }
        )

        for i, image in enumerate(images):
            content = [
                MessageSegment.text(f"ğŸ¨ å›¾ç‰‡ {i + 1}/{len(images)}"),
                MessageSegment.image(file=image["local_path"]),
            ]

            forward_messages.append(
                {
                    "type": "node",
                    "data": {
                        "name": "AIç»˜å›¾åŠ©æ‰‹",
                        "uin": str(bot.self_id),
                        "content": content,
                    },
                }
            )

        if isinstance(event, GroupMessageEvent):
            await bot.call_api(
                "send_group_forward_msg",
                group_id=event.group_id,
                messages=forward_messages,
            )
            logger.info(f"âœ… æˆåŠŸå‘é€ {len(images)} å¼ å›¾ç‰‡çš„ç¾¤èŠåˆå¹¶è½¬å‘æ¶ˆæ¯")
        else:
            await bot.call_api(
                "send_private_forward_msg",
                user_id=event.user_id,
                messages=forward_messages,
            )
            logger.info(f"âœ… æˆåŠŸå‘é€ {len(images)} å¼ å›¾ç‰‡çš„ç§èŠåˆå¹¶è½¬å‘æ¶ˆæ¯")

        return True

    except Exception as e:
        logger.error(f"å‘é€åˆå¹¶è½¬å‘æ¶ˆæ¯å¤±è´¥: {e}")
        return False


async def send_images_as_single_message(
    bot: Bot, event: MessageEvent, images: list, prompt: str
):
    """å°†æ‰€æœ‰å†…å®¹æ”¾åœ¨ä¸€ä¸ªæ¶ˆæ¯é‡Œå‘é€"""
    try:
        message_segments = [MessageSegment.text(f"ğŸ“ {prompt}")]

        for i, image in enumerate(images):
            message_segments.append(
                MessageSegment.text(f"\nğŸ¨ å›¾ç‰‡ {i + 1}/{len(images)}")
            )
            message_segments.append(MessageSegment.image(file=image["local_path"]))

        await bot.send(event, message_segments)
        logger.info(f"âœ… æˆåŠŸå‘é€åŒ…å« {len(images)} å¼ å›¾ç‰‡çš„å•æ¡æ¶ˆæ¯")
        return True

    except Exception as e:
        logger.error(f"å‘é€å•æ¡æ¶ˆæ¯å¤±è´¥: {e}")
        return False


async def _optimize_draw_prompt(user_message: UniMessage, user_id: str) -> str:
    """
    ä½¿ç”¨æ”¯æŒè§†è§‰åŠŸèƒ½çš„LLMä¼˜åŒ–ç”¨æˆ·çš„ç»˜å›¾æè¿°ã€‚
    æ”¯æŒâ€œæ–‡ç”Ÿå›¾â€çš„åˆ›æ„æ‰©å±•å’Œâ€œå›¾ç”Ÿå›¾â€çš„æŒ‡ä»¤ç†è§£ä¸èåˆã€‚
    """
    original_prompt = user_message.extract_plain_text().strip()
    logger.info(f"ğŸ¨ å¯ç”¨ç»˜å›¾æè¿°ä¼˜åŒ–ï¼Œæ­£åœ¨ä¸ºç”¨æˆ· '{user_id}' çš„æè¿°è¿›è¡Œæ¶¦è‰²...")

    system_prompt = """ä½ æ˜¯AIç»˜ç”»æç¤ºè¯å·¥ç¨‹å¸ˆã€‚ä»»åŠ¡ï¼šå°†ç”¨æˆ·è¾“å…¥è½¬åŒ–ä¸ºè¯¦ç»†çš„AIç»˜ç”»æç¤ºè¯ã€‚

æ ¸å¿ƒè§„åˆ™ï¼šæ¶¦è‰²æ—¶ä¸ä¸¢å¤±ç”¨æˆ·åŸæ–‡ä»»ä½•ç»†èŠ‚ã€‚

ã€åœºæ™¯ä¸€ï¼šçº¯æ–‡æœ¬è¾“å…¥ã€‘
æ‰©å±•ç®€çŸ­æè¿°ä¸ºå®Œæ•´åœºæ™¯ï¼Œè¡¥å……ï¼šä¸»ä½“ç‰¹å¾ã€åŠ¨ä½œå§¿æ€ã€ç¯å¢ƒèƒŒæ™¯ã€å…‰çº¿æ•ˆæœã€æ„å›¾è§†è§’ã€è‰ºæœ¯é£æ ¼ã€ç”»è´¨è¦æ±‚ã€‚

ç¤ºä¾‹ï¼š
- è¾“å…¥ï¼š"ä¸€åªçŒ«" 
- è¾“å‡ºï¼š"ç‰¹å†™é•œå¤´ï¼Œä¸€åªè‹±å›½çŸ­æ¯›çŒ«ï¼Œåˆåé˜³å…‰ä¸‹è¶´åœ¨æœ¨è´¨çª—å°æ‰“ç›¹ï¼Œæ¯›å‘ç»†èŠ‚æ¸…æ™°ï¼Œå…‰å½±æŸ”å’Œï¼Œç…§ç‰‡çº§çœŸå®æ„Ÿï¼Œ4kç”»è´¨"

ã€åœºæ™¯äºŒï¼šå›¾ç‰‡+æ–‡æœ¬è¾“å…¥ã€‘
å›¾ç‰‡ä¸ºä¸»ä½“ï¼Œæ–‡æœ¬ä¸ºä¿®æ”¹æŒ‡ä»¤ã€‚åªä¿®æ”¹æ–‡æœ¬æ˜ç¡®æåˆ°çš„éƒ¨åˆ†ï¼Œå…¶ä»–å…ƒç´ ä¿æŒåŸæ ·ã€‚

å·¥ä½œæµç¨‹ï¼š
1. **åˆ†æåŸå›¾**ï¼šè¯¦ç»†æè¿°ä¸»ä½“ã€å§¿æ€ã€æ„å›¾ã€ç¯å¢ƒã€å…‰ç…§ã€è‰²å½©ã€é£æ ¼
2. **è§£ææŒ‡ä»¤**ï¼šæå–å…·ä½“ä¿®æ”¹è¦æ±‚
3. **é‡æ„æç¤ºè¯**ï¼šä¿ç•™æœªæåŠå…ƒç´ ï¼Œç²¾ç¡®åº”ç”¨ä¿®æ”¹æŒ‡ä»¤ï¼Œæ·»åŠ ç”»è´¨è¯

ç¤ºä¾‹ï¼š
- è¾“å…¥ï¼š[é»‘å‘å¥³å­©å…¬å›­é•¿æ¤…å¾®ç¬‘å›¾] + "æ¢æˆå¤œæ™šä¸œäº¬è¡—å¤´èƒŒæ™¯"
- è¾“å‡ºï¼š"é»‘å‘å¥³å­©ï¼Œç™½è‰²è¿è¡£è£™ï¼Œé•¿æ¤…åå§¿å¾®ç¬‘è¡¨æƒ…ä¿æŒä¸å˜ï¼ŒèƒŒæ™¯æ›¿æ¢ä¸ºå¤œæ™šä¸œäº¬è¡—å¤´ï¼Œéœ“è™¹ç¯é—ªçƒï¼Œè½¦æ°´é©¬é¾™ï¼Œå…‰å½±æ–‘é©³ï¼Œç”µå½±æ„Ÿï¼Œ4kç”»è´¨"

ã€ç‰¹æ®ŠæŒ‡ä»¤ã€‘
æ•°é‡è¯ï¼ˆ"å››å¼ å›¾"ã€"ä¸¤ä¸ªç‰ˆæœ¬"ï¼‰å’Œå˜åŒ–è¯ï¼ˆ"ä¸åŒçš„"ã€"å¤šç§"ï¼‰éœ€ä¿ç•™åœ¨æç¤ºè¯å¼€å¤´ã€‚

ã€è¾“å‡ºæ ¼å¼ã€‘
ä¸¥æ ¼JSONæ ¼å¼ï¼Œä½¿ç”¨ä¸­æ–‡ï¼š
{
    "success": true,
    "original_prompt": "ç”¨æˆ·åŸå§‹æ–‡æœ¬",
    "analysis": "æ„å›¾åˆ†æ",
    "optimized_prompt": "ä¼˜åŒ–åçš„å®Œæ•´æç¤ºè¯"
}
"""

    try:
        logger.debug(
            f"ç»˜å›¾æè¿°ä¼˜åŒ–å°†ä½¿ç”¨æ¨¡å‹: {base_config.get('auxiliary_llm_model')}"
        )

        gen_config = None
        if "gemini" in base_config.get("auxiliary_llm_model").lower():
            gen_config = CommonOverrides.gemini_json()
        else:
            gen_config = LLMGenerationConfig(response_format={"type": "json_object"})

        content_parts = await unimsg_to_llm_parts(user_message)
        if not content_parts:
            logger.warning("æ— æ³•ä»ç”¨æˆ·æ¶ˆæ¯ä¸­æå–æœ‰æ•ˆå†…å®¹è¿›è¡Œä¼˜åŒ–ï¼Œå°†ä½¿ç”¨åŸå§‹æè¿°ã€‚")
            return original_prompt

        messages = [
            LLMMessage.system(system_prompt),
            LLMMessage.user(content_parts),
        ]

        llm_response = await generate(
            messages,
            model=base_config.get("auxiliary_llm_model"),
            **gen_config.to_dict(),
        )
        response_text = llm_response.text

        json_match = re.search(r"\{.*\}", response_text, re.DOTALL)
        if not json_match:
            logger.warning("æè¿°ä¼˜åŒ–LLMæœªè¿”å›æœ‰æ•ˆçš„JSONç»“æ„ï¼Œå°†ä½¿ç”¨åŸå§‹æè¿°ã€‚")
            return original_prompt

        parsed_json = json.loads(json_match.group())

        if parsed_json.get("success") and (
            optimized := parsed_json.get("optimized_prompt")
        ):
            logger.info(f"âœ… æè¿°ä¼˜åŒ–æˆåŠŸã€‚ä¼˜åŒ–å: '{optimized}'")
            return optimized
        else:
            logger.warning("æè¿°ä¼˜åŒ–LLMè¿”å›å†…å®¹ä¸ç¬¦åˆé¢„æœŸï¼Œå°†ä½¿ç”¨åŸå§‹æè¿°ã€‚")
            return original_prompt

    except Exception as e:
        logger.error(f"âŒ ç»˜å›¾æè¿°ä¼˜åŒ–å¤±è´¥ï¼Œå°†ä½¿ç”¨åŸå§‹æè¿°ã€‚é”™è¯¯: {e}")
        return original_prompt


@ai_draw.handle()
async def ai_draw_handler(
    bot: Bot, event: MessageEvent, result: CommandResult, msg: UniMsg
):
    """aiç»˜å›¾å‘½ä»¤å¤„ç†å™¨"""
    user_id_str = event.get_user_id()
    is_superuser = await SUPERUSER(bot, event)

    if not is_superuser:
        if not base_config.get("enable_ai_draw"):
            logger.info(f"ç”¨æˆ· {user_id_str} å°è¯•ä½¿ç”¨aiç»˜å›¾ï¼Œä½†åŠŸèƒ½å·²è¢«ç®¡ç†å‘˜ç¦ç”¨")
            return

    try:
        current_text = ""
        replied_text = ""
        full_message_for_media = msg

        raw_text = msg.extract_plain_text().strip()
        if raw_text.startswith("aiç»˜å›¾"):
            current_text = raw_text[4:].strip()
        elif raw_text.startswith("aiç»˜ç”»"):
            current_text = raw_text[4:].strip()

        if event.reply and event.reply.message:
            reply_unimsg = message_to_unimessage(event.reply.message)
            replied_text = reply_unimsg.extract_plain_text().strip()
            full_message_for_media = msg + reply_unimsg
            logger.debug("å·²åˆå¹¶å¼•ç”¨æ¶ˆæ¯çš„åª’ä½“å†…å®¹ã€‚")

        prompt_parts = []
        if current_text:
            prompt_parts.append(current_text)
        if replied_text:
            prompt_parts.append(replied_text)
        prompt = ",".join(prompt_parts)

        image_file_path = None
        if image_segments := full_message_for_media[UniImage]:
            first_image = image_segments[0]
            logger.info("æ£€æµ‹åˆ°å›¾ç‰‡è¾“å…¥ï¼Œå‡†å¤‡ç”¨äºç»˜å›¾...")
            image_data = None
            if first_image.raw:
                image_data = first_image.raw
            elif first_image.path:
                async with aiofiles.open(first_image.path, "rb") as f:
                    image_data = await f.read()
            elif first_image.url:
                async with httpx.AsyncClient() as client:
                    resp = await client.get(first_image.url)
                    resp.raise_for_status()
                    image_data = resp.content

            if image_data:
                temp_dir = Path(tempfile.gettempdir()) / "multimodal_ai" / "temp_images"
                temp_dir.mkdir(parents=True, exist_ok=True)
                timestamp = int(time.time() * 1000)
                temp_filename = f"upload_{timestamp}.png"
                image_file_path = temp_dir / temp_filename

                async with aiofiles.open(image_file_path, "wb") as f:
                    await f.write(image_data)

                logger.info(f"å›¾ç‰‡å·²ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶: {image_file_path}")

        if not prompt and not image_file_path:
            await ai_draw.finish(
                "è¯·æä¾›å›¾ç‰‡æè¿°æˆ–é™„å¸¦å›¾ç‰‡ï¼Œä¾‹å¦‚ï¼šaiç»˜å›¾ ä¸€åªå¯çˆ±çš„å°çŒ«"
            )
            return

        optimizer_input_message = UniMessage.text(prompt)
        if image_file_path:
            optimizer_input_message.append(UniImage(path=image_file_path))

        if base_config.get("enable_draw_prompt_optimization"):
            final_prompt_or_list = await _optimize_draw_prompt(
                user_message=optimizer_input_message,
                user_id=user_id_str,
            )
        else:
            final_prompt_or_list = prompt

        if isinstance(final_prompt_or_list, list):
            logger.info(
                f"ä¼˜åŒ–åçš„æè¿°æ˜¯ä¸€ä¸ªåŒ…å« {len(final_prompt_or_list)} éƒ¨åˆ†çš„åˆ—è¡¨ï¼Œå°†åˆå¹¶ä¸ºå•ä¸ªæç¤ºè¯ã€‚"
            )
            final_prompt = " ".join(map(str, final_prompt_or_list))
        else:
            final_prompt = str(final_prompt_or_list)

        logger.info(f"ç”¨æˆ· {user_id_str} è¯·æ±‚aiç»˜å›¾: {final_prompt[:100]}...")
        if image_file_path:
            logger.info(f"åŒ…å«å›¾ç‰‡æ–‡ä»¶: {image_file_path}")

        request = await draw_queue_manager.add_request(
            user_id_str, final_prompt, str(image_file_path) if image_file_path else None
        )

        queue_position = request.queue_position
        is_browser_cooling = draw_queue_manager.is_browser_in_cooldown()

        if (queue_position and queue_position > 1) or is_browser_cooling:
            message = (
                f"ğŸ“‹ æ‚¨çš„è¯·æ±‚å·²åŠ å…¥é˜Ÿåˆ—\n"
                f"ğŸ”¢ é˜Ÿåˆ—ä½ç½®: {queue_position}\n"
                f"â±ï¸ é¢„ä¼°ç­‰å¾…: {request.estimated_wait_time:.1f}ç§’"
            )

            if is_browser_cooling:
                cooldown_remaining = draw_queue_manager.get_browser_cooldown_remaining()
                message += f"\nğŸ”„ æµè§ˆå™¨å†·å´ä¸­ï¼Œå‰©ä½™: {cooldown_remaining:.1f}ç§’"

            message += "\nğŸ¨ è¯·è€å¿ƒç­‰å¾…..."
            await ai_draw.send(message)
        else:
            await ai_draw.send("ğŸ¨ æ­£åœ¨ç”Ÿæˆå›¾ç‰‡ï¼Œè¯·ç¨å€™...")

        draw_queue_manager.start_queue_processor()

        completed_request = await draw_queue_manager.wait_for_request_completion(
            request.request_id,
            timeout=600.0,
        )

        if not completed_request:
            await ai_draw.finish("âŒ è¯·æ±‚å¤„ç†è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•")
            return

        result_data = completed_request.result
        if not result_data:
            error_msg = completed_request.error or "æœªçŸ¥é”™è¯¯"
            await ai_draw.finish(f"âŒ å›¾ç‰‡ç”Ÿæˆå¤±è´¥: {error_msg}")
            return

        if result_data["success"]:
            images = result_data["images"]
            if images:
                if len(images) == 1:
                    await ai_draw.finish(
                        MessageSegment.image(file=images[0]["local_path"])
                    )
                else:
                    success = await send_images_as_forward(
                        bot, event, images, final_prompt
                    )
                    if not success:
                        logger.warning("åˆå¹¶è½¬å‘å¤±è´¥ï¼Œå›é€€åˆ°å•æ¡æ¶ˆæ¯å‘é€")
                        await send_images_as_single_message(
                            bot, event, images, final_prompt
                        )

                    await ai_draw.finish()
            else:
                await ai_draw.finish("âŒ å›¾ç‰‡ç”Ÿæˆå¤±è´¥ï¼šæœªè·å–åˆ°å›¾ç‰‡æ•°æ®")
        else:
            error_msg = result_data.get("error", "æœªçŸ¥é”™è¯¯")
            logger.error(f"å›¾ç‰‡ç”Ÿæˆå¤±è´¥: {error_msg}")
            await ai_draw.finish(f"âŒ å›¾ç‰‡ç”Ÿæˆå¤±è´¥: {error_msg}")

        if image_file_path and image_file_path.exists():
            try:
                Path(image_file_path).unlink()
                logger.debug(f"å·²æ¸…ç†ä¸´æ—¶å›¾ç‰‡æ–‡ä»¶: {image_file_path}")
            except Exception as e:
                logger.warning(f"æ¸…ç†ä¸´æ—¶å›¾ç‰‡æ–‡ä»¶å¤±è´¥: {e}")

    except Exception as e:
        if e.__class__.__name__ != "FinishedException":
            logger.error(f"å¤„ç†aiç»˜å›¾è¯·æ±‚å¤±è´¥: {e}")
            friendly_message = get_user_friendly_error_message(e)
            await ai_draw.finish(f"aiç»˜å›¾å¤±è´¥: {friendly_message}")
